机器学习 1 入门篇
################################################################

推荐系统简介
****************************************************************

* 推荐系统概述

::

	– 推荐系统的目的
	– 推荐系统的应用
	– 推荐系统的基本思想 
	– 推荐系统分类

* 推荐算法简介

::

	– 基于人口统计学的推荐 
	– 基于内容的推荐
	– 基于协同过滤的推荐
	– 混合推荐

* 推荐系统评测

推荐系统的目的 1
=================================================================

* 信息过载 
* 推荐系统

	* 推荐系统是信息过载所采用的措施，面对海量的数据信息， 从中快速推荐出符合用户特点的物品。解决一些人的“选择 恐惧症”;面向没有明确需求的人。
	* 解决如何从大量信息中找到自己感兴趣的信息。
	* 解决如何让自己生产的信息脱颖而出，受到大众的喜爱。

推荐系统的目的 2
=================================================================

|image0|

* 让用户更快更好的获取到自己 需要的内容
* 让内容更快更好的推送到喜欢 它的用户手中
* 让网站(平台)更有效的保留 用户资源

.. note::

	好的推荐系统——让三方共赢. 

推荐系统的基本思想
=================================================================

* 利用用户和物品的特征信息，给用户推荐那些具有用户喜欢的特征的物品。
* 利用用户喜欢过的物品，给用户推荐与他喜欢过的物品相似的物品。
* 利用和用户相似的其他用户，给用户推荐那些和他们兴趣爱好相似的其他用 户喜欢的物品。

|image1|

* 知你所想，精准推送: 利用用户和物品的特征信息，给用户推荐那些具有用户喜欢的特征的物品。
* 物以类聚: 利用用户喜欢过的物品，给用户推荐与他喜欢过的物品相似的物品。
* 人以群分: 利用和用户相似的其他用户，给用户推荐那些和他们兴趣爱好相似的其他用户喜 欢的物品。

推荐系统的数据分析
=================================================================

|image2|

* 要推荐物品或内容的元数据，例如关键字，分类标签，基因描述等;
* 系统用户的基本信息，例如性别，年龄，兴趣标签等
* 用户的行为数据，可以转化为对物品或者信息的偏好，根据应用本身的不同， 可能包括用户对物品的评分，用户查看物品的记录，用户的购买记录等。这 些用户的偏好信息可以分为两类:

	* 显式的用户反馈:这类是用户在网站上自然浏览或者使用网站以外，显式的提供 反馈信息，例如用户对物品的评分，或者对物品的评论。
	* 隐式的用户反馈:这类是用户在使用网站是产生的数据，隐式的反应了用户对物 品的喜好，例如用户购买了某物品，用户查看了某物品的信息等等

推荐系统的分类
=================================================================

* 根据实时性分类 

	* 离线推荐
	* 实时推荐

* 根据推荐原则分类

	* 基于相似度的推荐 
	* 基于知识的推荐
	* 基于模型的推荐

* 根据推荐是否个性化分类 
	
	* 基于统计的推荐
	* 个性化推荐

* 根据数据源分类

	* 基于人口统计学的推荐 
	* 基于内容的推荐
	* 基于协同过滤的推荐

|image3|

推荐算法简介
=================================================================

* 基于人口统计学的推荐 
* 基于内容的推荐
* 基于协同过滤的推荐
* 混合推荐

基于人口统计学的推荐算法
-----------------------------------------------------------------

|image4|

基于内容的推荐算法
-----------------------------------------------------------------

|image5|

基于协同过滤的推荐算法
-----------------------------------------------------------------

* 协同过滤(Collaborative Filtering，CF) 
* 基于近邻的协同过滤

	* 基于用户(User-CF) 
	* 基于物品(Item-CF)

* 基于模型的协同过滤

	* 奇异值分解(SVD) 
	* 潜在语义分析(LSA) 
	* 支撑向量机(SVM)

|image6|

协同过滤(CF)推荐方法
-----------------------------------------------------------------

* 基于内容(Content based, CB) 主要利用的是用户评价过的物品内容特征，而 CF 方法还可以利用其它用户评分富哦的物品内容。
* CF 可以解决 CB 的一些局限
	
	*  物品内容不完全或者难以获得时， 依然可以通过其它用户的反馈推荐
	*  CF基于用户之间对物品的评价质量，避免了CB仅依赖内容可能造成的对物品质量判断的干扰
	*  CF推荐不收内容限制，只要其它类似用户给出了对不同物品的兴趣，CF就可以给用户推荐出内容差异很大的物品（单有某种内在关系）

* 分为两类：基于近邻和基于模型

基于用户的协同过滤
-----------------------------------------------------------------

|image7|

基于物品的协同过滤
-----------------------------------------------------------------

|image8|

混合推荐
-----------------------------------------------------------------

* 实际网站的推荐系统往往都不是单纯只采用了某一种推荐的机制和策略，往往是将多 个方法混合在一起，从而达到更好的推荐效果。比较流行的组合方法有:
* 加权混合

	* 用线性公式(linear formula)将几种不同的推荐按照一定权重组合起来，具体权重的值需要在测试数据集上反复实验，从而达到最好的推荐效果

* 切换混合

	* 切换的混合方式，就是允许在不同的情况(数据量，系统运行状况，用户和物品的数目等)下， 选择最为合适的推荐机制计算推荐

* 分区混合

	* 采用多种推荐机制，并将不同的推荐结果分不同的区显示给用户

* 分层混合

	* 采用多种推荐机制，并将一个推荐机制的结果作为另一个的输入，从而综合各个推荐机制的优 缺点，得到更加准确的推荐

推荐系统评测
=================================================================

* 让用户更快更好的获取到自己 需要的内容
* 让内容更快更好的推送到喜欢 它的用户手中
* 让网站(平台)更有效的保留 用户资源

推荐系统实验方法
=================================================================

* 离线实验

	* 通过体制系统获得用户行为数据，并按照一定格式生成一个标准的数据集 – 将数据集按照一定的规则分成训练集和测试集
	* 在训练集上训练用户兴趣模型，在测试集上进行预测
	* 通过事先定义的离线指标评测算法在测试集上的预测结果

* 用户调查

	* 用户调查需要有一些真实用户，让他们在需要测试的推荐系统上完成一些任务;我们需要记录他们的行为，并让他们回答一些问题;最后进行分析

* 在线实验 – AB测试

推荐系统评测指标
=================================================================

::

	• 预测准确度 
	• 用户满意度 
	• 覆盖率
	• 多样性
	• 惊喜度
	• 信任度
	• 实时性
	• 健壮性
	• 商业目标

推荐准确度评测
=================================================================

* 评分预测

	* 很多网站都有让用户给物品打分的功能，如果知道用户对物品的历史评分，就可以从中学习一个兴趣模型，从而预测用户对新物品的评分
	* 评分预测的准确度一般用均方根误差(RMSE)或平均绝对误差(MAE)计算

|image9|

* Top-N推荐

	* 网站提供推荐服务时，一般是给用户一个个性化的推荐列表，这种推荐叫做 Top-N 推荐
	* Top-N推荐的预测准确率一般用精确率(precision)和召回率(recall)来度量

准确率、精确率和召回率
=================================================================

* 假如某个班级有男生80人,女生20人,共计100人.目标是找出所有女生. 现在某人挑选出50个人,其中20人是女生,另外还错误的把30个男生也当作女生挑选出来了. 作为评估者的你需要来评估(evaluation)下他的工作
* 将挑选结果用矩阵示意来表示: 定义 TP, FN, FP, TN 四种分类情况。

::

								相关(Relevant),正类								无关(NonRelevant),负类
	被检索到(Retrieved)			true positives(TP 选中的人中，其中 20 人是女生)		false positives(FP 错误把 30 个男生当女生选出)
	未被检索到(Not Retrieved)		false negatives(FN 未选出的人中, 0 人是女生)		true negatives(TN 未选出的人中, 有 50 人非女生)

* 准确率(accuracy)的公式是,其定义是: 对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。也就是损失函数是0-1损失时测试数据集上的准确率 A = (20+50) / 100 = 70%
* 精确率(precision)的公式是,它计算的是所有被检索到的item中,"应该被检索到"的item占的比例  P = 20 / (20+30) = 40%
* 召回率(recall)的公式是,它计算的是所有检索到的item占所有"应该检索到的item"的比例 R = 20 / (20 + 0) = 100%

数学基础
****************************************************************************************************

主要内容

::

	线性代数知识
	微积分知识
	概率与统计知识

线性代数
====================================================================================================

主要内容 

::

	什么是矩阵
	矩阵中的基本概念
	矩阵的加法
	矩阵的乘法
	矩阵的转置
	矩阵的运算法则
	矩阵的逆

矩阵
----------------------------------------------------------------------------------------------------

* 矩阵（Matrix）是一个按照长方形阵列排列的复数或实数集合。
* 矩阵最早来自于方程组的系数及常数所构成的方阵，最初是用来解决线性方程求解的工具。
* 矩阵是高等代数中常见工具，也常见于统计分析等应用数学学科中，矩阵在物理学和计算机科学中都有应用。
* 矩阵的运算时数值分析领域的重要问题。

|image10|

|image11|

|image12|

特殊矩阵
----------------------------------------------------------------------------------------------------

|image13|

|image14|

|image15|

矩阵中的概念
----------------------------------------------------------------------------------------------------

|image16|

矩阵的加法
----------------------------------------------------------------------------------------------------

|image17|

* 把矩阵的对应位元素相加
* 矩阵的形状必须一致，即必须是同型矩阵

|image18|

|image19|

矩阵的乘法
----------------------------------------------------------------------------------------------------

* 数与矩阵相乘: 数值与矩阵每一个元素相乘

|image20|

* 矩阵与矩阵相乘: 左矩阵的每一行与右矩阵的每一列, 对应每一个元素相乘

|image21|

|image22|

|image23|

|image24|

|image25|

|image26|

|image27|

|image28|

矩阵的转置
----------------------------------------------------------------------------------------------------

|image29|

| 把矩阵 A 的行换成相同序数的列，得到一个新矩阵，叫做 A 的转置矩阵，记作 A
| 行变列，列变行
| A为m×n矩阵，转置之后为n×m矩阵

矩阵的运算法则
----------------------------------------------------------------------------------------------------

|image30|

矩阵的逆
----------------------------------------------------------------------------------------------------

|image31|

微积分基本知识
====================================================================================================

导数
----------------------------------------------------------------------------------------------------

|image32|

偏导数
----------------------------------------------------------------------------------------------------

|image33|

方向导数
----------------------------------------------------------------------------------------------------

|image34|

梯度
----------------------------------------------------------------------------------------------------

|image35|

凸函数和凹函数（注意：这里的凸和凹是指下凸和下凹）
----------------------------------------------------------------------------------------------------

|image36|

概率统计基础知识
====================================================================================================

常用统计变量
----------------------------------------------------------------------------------------------------

|image37|

常见的概率分布
----------------------------------------------------------------------------------------------------

|image38|

重要的概率公式（注意，第一个条件概率公式的意思是A发生的情况下B发生的概率，等于AB同时发生的概率比上A发生的概率）
----------------------------------------------------------------------------------------------------

|image39|

机器学习基础
****************************************************************

主要内容

::

	机器学习的概念 
	机器学习主要分类 
	监督学习深入理解
		监督学习三要素
		监督学习模型评估策略
		监督学习模型求解算法

机器学习的概念
====================================================================================================

* 机器学习是什么
* 机器学习的开端
* 机器学习的定义
* 机器学习的过程
* 机器学习示例

机器学习是什么
----------------------------------------------------------------------------------------------------

* 什么是学习

::

	从人的学习说起
	学习理论; 从时间经验中总结
	在理论上推导; 在实践中检验
	通过各种手段获取知识或技能的过程

* 机器怎么学习?

::

	处理某个特定的任务，以大量的“经验”为基础
	对任务完成的好坏，给予一定的评判标准
	通过分析经验数据，任务完成得更好了

机器学习的开端
----------------------------------------------------------------------------------------------------

1952年，IBM的Arthur Samuel（被誉为“机器学习之父”）设计了一款可以学习的西洋跳棋程序

他能通过观察棋子的走位来构建新的模型，并用其提高自己的下棋技巧

Samuel和这个程序进行多场对弈后发现，随着时间的推移，程序的棋艺变得越来越好。

机器学习的定义
----------------------------------------------------------------------------------------------------

机器学习（Machine Learning，ML）主要研究计算机系统对于特定任务的性能，逐步进行改善的算法和统计模型

通过输入海量训练数据对模型进行训练，使模型掌握数据所蕴含的潜在规律，进而对新输入的数据进行准确的分类或预测

是一门多领域交叉学科，设计概率论、统计学、逼近论、凸优化、算法复杂度理论等多门学科。专门研究计算机怎么样模拟或实现人类的学习行为，获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。

机器学习的过程
----------------------------------------------------------------------------------------------------

|image40|

机器学习主要分类
----------------------------------------------------------------------------------------------------

|image41|

::

	有监督学习：提供数据并提供数据对应结果的机器学习过程
	无监督学习：提供数据并且不提供数据对应结果的机器学习过程
	强化学习：通过与环境交互并获取延迟返回进而改进行为的学习过程

|image43|

* 无监督学习

无监督学习（Unsupervised Learning）算法采用一组仅包含输入的数据，通过寻找数据中的内在结构来进行样本点的分组或聚类

算法从没有被标记或分类的测试数据中学习.

无监督学习算法不是影响反馈，而是识别数据中的共性特征；对于一个新数据，可以通过判断其中是否存在这种特征，来做出相应的反馈

无监督学习的核心应用是统计学中的密度估计和聚类分析.

* 无监督学习应用

无监督聚类应用的一个列子就是谷歌新闻中

谷歌新闻每天都会收集很多新闻内容。它将这些新闻分组，组成有关联的新闻，然后按主题显示给用户

谷歌新闻做的就是搜索新闻事件，自动把他们聚类到一起；这些新闻事件圈是同一主题的.

* 监督学习

监督学习（Supervised Learning）算法构建了包含输入和所需输出的一组数据的数学模型。这些数据称为训练数据，由一组训练样本组成

监督学习主要包含分类和回归

当输出被限制为有限的一组值（离散数据值）时使用分类算法；当输出可以具有范围内的任何数据（连续数值）时使用回归算法

相似度学习是和回归和分类都密切相关的一类监督机器学习，他的目标是使用相似性函数从样本中学习，这个函数可以度量两个对象之间的相似度或关联度。他在排名、推荐系统、视觉识别跟踪、人脸识别等方面有很好的应用场景.

|image42|

监督学习深入介绍
----------------------------------------------------------------------------------------------------

* 监督学习三要素

|image44|

模型（Model）：总结数据的内在规律，用数学函数描述的系统

策略（startegy）：选取最优模型的评价准则

算法（Algorithm）：选取最优模型的具体方法

* 监督学习实现步骤

得到一个有限的训练数据集

确定包含所有学习模型的集合

确定模型选择的准则，也就是学习策略

实现求解最优模型的算法，也就是学习算法

通过学习算法选择最优模型

利用得到的最优模型，对新数据进行预测或分析

|image45|

模型评估策略
----------------------------------------------------------------------------------------------------

::

	模型评估
	    训练集和测试集
	    损失函数和经验风险
	    训练误差和测试误差

	模型选择
	    过拟合和欠拟合
	    正则化和交叉验证

* 训练集和测试集

将数据输入到模型中训练出了对应模型，但是模型的效果好不好？我们需要对模型的好坏进行评估

将用来训练模型的数据称为训练集，将用来测试模型好坏的集合称为测试集

训练集：输入到模型中对模型进行训练的数据集合

测试集：模型训练完成后测试训练效果的数据集合

* 损失函数

损失函数用来衡量模型预测误差的大小

定义：选取模型f为决策函数，对于给定的输入参数X，f(X)为预测结果，Y为真实结果；f(X)和Y之间可能会有偏差，我们就用一个损失函数（loss function）来度量预测偏差的程度，记作L(Y,f(X))

损失函数是系数的函数

损失函数值越小，模型就越好

|image46|

* 经验风险

|image47|

* 训练误差和测试误差

|image48|

* 过拟合和欠拟合

|image49|

|image50|

[欠拟合]

模型没有很好的扑捉到数据特征，特征集过小，导致模型补鞥呢很好滴拟合数据，称之为欠拟合（under-fitting）

欠拟合的本质是对数据的特征“学习”得不够

例如：想分辨一只猫，只给出了四条腿、两只眼睛、有尾巴这三个特征，那么由此训练出来的模型根本无法分辨猫

[过拟合]

把训练数据学习的太彻底，以至于把噪声数据的特征也学习到了，特征集过大，这样就会导致在后期测试的时候不能够很好地识别数据，即不能正确的分类，模型泛化能力太差，称之为过拟合（over-fitting）

例如，想分辨一只猫，给出了四条腿、两只眼睛、一条有尾巴、叫声、颜色，能够捕捉老鼠、喜欢吃鱼、。。。，然后签好所有的训练数据的猫都是白色，难么这个白色是一个噪声数据，会干扰判断，结果模型吧颜色是白色也学习到了，而白色是局部样本的特征，不是全局特征，就造成了输入一个黑猫的数据，判断出不是猫

* 模型的选择

当模型复杂度增大时，训练误差会逐渐减小并趋向于0；而测试误差会先减小，达到最小值之后再增大

当模型复杂度过大时，就会发生过拟合；所以模型复杂度应适当

|image51|

* 正则化

结构风险最小化（Structural Risk Minimization，SRM）

是在ERM基础上，为了防止过拟合而提出来的策略

在经验风险上加上表示模型复杂度的正则化项（regularizer），或者叫做惩罚项

正则化项一般是模型复杂度的单调递增函数，即模型越复杂，正则化值越大

结构风险最小化的典型实现是正则化（regularization）

|image52|

* 奥卡姆剃刀

奥卡姆剃刀（Occam `srazor）原理：如无必要，勿增实体

正则化符合奥卡姆剃刀原理。它的思想是：在所有可能选择的模型中，我们应该选择能够很好地解释已知数据并且十分简单的模型

如果简单的模型已经够用，我们不应该一味地追求更小的训练误差，而把模型变得越来越复杂

* 交叉验证

::

	数据集划分
		如果样本数据充足，一种简单方法是随机将数据集切成三部门：训练集（training set）、验证集（validation set）和测试集（test set）
		训练集用于训练模型，验证集用于模型选择，测试集用于学习方法评估
	数据不充足时，可以重复地利用数据--交叉验证（cross validation）
		简单交叉验证
			数据随机分为两部分，如70%作为训练集，剩下30%作为测试集
			训练集在不同的条件下（如参数个数）训练模型，得到不同的模型
			在测试集上评价各个模型的测试误差，选出最优模型
	S折交叉验证
		将数据随机切分为S哥互不相交、相同大小的子集；S-1个做训练集，剩下一个做测试集
		重复进行训练集、测试集的选取、有S种可能的选择
	留一交叉验证

* 分类和回归

监督学习问题主要可以划分为两类，即分类问题和回归问题

::

	- 分类问题预测数据属于那一类别。-- 离散
	- 回归问题根据数据预测一个数值。-- 连续

通俗地讲，分类问题就是预测数据属于哪一种类型，就像上面的房屋出售预测，通过大量数据训练模型，然后去预测某个给定房屋能不能出售出去，属于能够出售类型还是不能出售类型

回归问题就是预测一个数值，比如给出房屋一些特征，预测房价

如果上面的房屋出售的问题改为预测房屋出售的概率，得到的结果将不是可以抽出（1）和不能售出（0），将会是一个连续的数值，例如0.5，这就变成一个回归问题

* 分类问题

|image53|

精确率和召回率
----------------------------------------------------------------------------------------------------

评价分类器性能的指标一般是分类准确率（Accuracy），它定义为分类器对测试集正确分类的样本数与总样本数之比

对于二类分类问题，常用的评价指标是精确率（Precision）与召回率（Recall）

通常以关注的类为正类，其它为负类，按照分类器在测试集上预测的正确与否，会有四种情况出现，他们的总数分别记作：

::

	TP（true positive）：将正类预测为正类的数目
	FN（false negative）：将正类预测为负类的数目
	FP（false positive）：将负类预测为正类的数目
	TN（true negative）：将负类预测为负类的数目

|image54|

|image55|

回归问题
----------------------------------------------------------------------------------------------------

回归问题用于预测输入变量和输出变量之间的关系

回归模型就是表示从输入变量到输出变量之间映射的函数

回归问题的学习等价于函数拟合：选择一条函数曲线，使其很好地拟合已知数据，并且能够很好地预测未知数据

|image56|

* 回归问题的分类

::

	按照输入变量个数：一元回归和多元回归
	按照模型类型：线性回归和非线性回归

回归学习的损失函数--平方损失函数

如果选取平方损失函数作为损失函数，回归问题可以用著名的最小二乘法（Least squares）来求解

模型求解算法（学习算法）
----------------------------------------------------------------------------------------------------

::

	梯度下降算法
	牛顿法和拟牛顿法

* 梯度下降算法

梯度下降（gradient descent）是一种常用的一阶优化方法，是求解无约束优化问题最简单、最经典的方法之一

梯度方向：函数变化增长最快的方向（变量沿此方向变化时函数增长最快）

负梯度方向：函数变化减少最快的方向（变量沿此方向变化时函数减少最快）

损失函数是系数的函数，那么如果系统沿着损失函数的负梯度方向变化，此时损失函数减少最快，能够以最快速递下降到极小值

|image57|

|image58|

* 牛顿法和拟牛顿法

|image59|

.. attention::

	一阶偏导表示变化率; 二阶偏导表示变化率的变化率。

.. |image0| image:: /_static/machine_learn_intro/WX20200809-222454@2x.webp
.. |image1| image:: /_static/machine_learn_intro/WX20200809-225536@2x.webp
.. |image2| image:: /_static/machine_learn_intro/WX20200810-110804@2x.webp
.. |image3| image:: /_static/machine_learn_intro/WX20200810-111305@2x.webp
.. |image4| image:: /_static/machine_learn_intro/WX20200810-111603@2x.webp
.. |image5| image:: /_static/machine_learn_intro/WX20200810-111727@2x.webp
.. |image6| image:: /_static/machine_learn_intro/WX20200810-112006@2x.webp
.. |image7| image:: /_static/machine_learn_intro/WX20200810-122425@2x.webp
.. |image8| image:: /_static/machine_learn_intro/WX20200810-122651@2x.webp
.. |image9| image:: /_static/machine_learn_intro/WX20200810-123502@2x.webp
.. |image10| image:: /_static/machine_learn_intro/WX20200810-145059@2x.webp
.. |image11| image:: /_static/machine_learn_intro/1479352-20200401195908881-1738921074.png
.. |image12| image:: /_static/machine_learn_intro/1479352-20200401200013120-1169040296.png
.. |image13| image:: /_static/machine_learn_intro/1479352-20200401200156447-230454338.png
.. |image14| image:: /_static/machine_learn_intro/1479352-20200401200211839-979307584.png
.. |image15| image:: /_static/machine_learn_intro/1479352-20200401200325517-1506190479.png
.. |image16| image:: /_static/machine_learn_intro/1479352-20200401200300414-628537503.png
.. |image17| image:: /_static/machine_learn_intro/1479352-20200401200402914-1602750037.png
.. |image18| image:: /_static/machine_learn_intro/WX20200810-164046@2x.webp
.. |image19| image:: /_static/machine_learn_intro/WX20200810-164339@2x.webp
.. |image20| image:: /_static/machine_learn_intro/WX20200810-165452@2x.webp
.. |image21| image:: /_static/machine_learn_intro/WX20200810-165713@2x.webp
.. |image22| image:: /_static/machine_learn_intro/17027103-b84d28924231853e.webp
.. |image23| image:: /_static/machine_learn_intro/17027103-6dd2992e19d71cbf.webp
.. |image24| image:: /_static/machine_learn_intro/WX20200810-170357@2x.webp
.. |image25| image:: /_static/machine_learn_intro/WX20200810-170610@2x.webp
.. |image26| image:: /_static/machine_learn_intro/WX20200810-170715@2x.webp
.. |image27| image:: /_static/machine_learn_intro/WX20200810-170822@2x.webp
.. |image28| image:: /_static/machine_learn_intro/WX20200810-170931@2x.webp
.. |image29| image:: /_static/machine_learn_intro/WX20200810-171157@2x.webp
.. |image30| image:: /_static/machine_learn_intro/WX20200810-171333@2x.webp
.. |image31| image:: /_static/machine_learn_intro/1479352-20200401200908640-1581583322.png
.. |image32| image:: /_static/machine_learn_intro/1479352-20200401200958215-685619373.png
.. |image33| image:: /_static/machine_learn_intro/1479352-20200401201031640-695805418.png
.. |image34| image:: /_static/machine_learn_intro/1479352-20200401201050008-1550650607.png
.. |image35| image:: /_static/machine_learn_intro/1479352-20200401201111314-867616174.png
.. |image36| image:: /_static/machine_learn_intro/1479352-20200401201222887-1255239858.png
.. |image37| image:: /_static/machine_learn_intro/1479352-20200401201302322-868652676.png
.. |image38| image:: /_static/machine_learn_intro/1479352-20200401201333820-37937804.png
.. |image39| image:: /_static/machine_learn_intro/1479352-20200401201401611-1287874821.png
.. |image40| image:: /_static/machine_learn_intro/aHR0cDovLzQ3.jpeg
.. |image41| image:: /_static/machine_learn_intro/aHR0cDovLzQ3LjExMi4yMjMuOTQvd.jpeg
.. |image42| image:: /_static/machine_learn_intro/aHR0cDovLzQ3LjExMi4yMjMuOTQvd3AtY29.jpg
.. |image43| image:: /_static/machine_learn_intro/WX20200811-093150@2x.webp
.. |image44| image:: /_static/machine_learn_intro/aHR0cDovLzQ3LjExMi4yMjMuOTQvd3AtY29udGVu.png
.. |image45| image:: /_static/machine_learn_intro/aHR0cDovLzQwww.png
.. |image46| image:: /_static/machine_learn_intro/aHRAtY29udGVudCssss.png
.. |image47| image:: /_static/machine_learn_intro/aHR0cDovLzQ3LjEuZw.png
.. |image48| image:: /_static/machine_learn_intro/aHR0cDovnBuZw.png
.. |image49| image:: /_static/machine_learn_intro/aHR0cDovLzQw.webp
.. |image50| image:: /_static/machine_learn_intro/aHR0cssssxLnBuZw.png
.. |image51| image:: /_static/machine_learn_intro/aHR0cDovLzQ3LjExnBuZw.jpeg
.. |image52| image:: /_static/machine_learn_intro/aHR0cDovLzQ3LjExMi4yMjM.jpeg
.. |image53| image:: /_static/machine_learn_intro/IwMjAvMDUvJUU1JTlCJUJFJUU3JTg5JTg3LTM0LnBuZw.jpeg
.. |image54| image:: /_static/machine_learn_intro/aHR0cDovnBuZw.jpeg
.. |image55| image:: /_static/machine_learn_intro/aHR0cDovLzUJFJUU3JTg5JTg3LTM1LnBuZw.jpeg
.. |image56| image:: /_static/machine_learn_intro/aHR0cUvJUU1JTlCJUJFJUU3JTg5JTg3LTM2LnBuZw.jpeg
.. |image57| image:: /_static/machine_learn_intro/aHR0cDovLzBuZw.jpeg
.. |image58| image:: /_static/machine_learn_intro/aHR0cDovLzQ3LjExMi4BuZw.jpeg
.. |image59| image:: /_static/machine_learn_intro/aHR0cUU1JTlCJUJTg3LTQwLnBuZw.jpeg































































